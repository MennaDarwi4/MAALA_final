{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125f7879",
   "metadata": {},
   "source": [
    "Search Engine With Tools And Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d6908094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arxiv\n",
    "#tools creation \n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "54275842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_char_max=250)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3d16a272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b1f0846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d66a780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom tools[rag tools]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c44c1fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028AE8F372F0>, search_kwargs={})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "documents= RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "from langchain_huggingface.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") \n",
    "vectordb = FAISS.from_documents(documents, embeddings) \n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "731809a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "abe8f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"LangSmith_Search\",\n",
    "    description=\"Search any information about LangSmith\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d087843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dd029aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all this tools with agents and llms\n",
    "#tools , llm -->agentexecutor\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9cb1c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.getenv(\"QROQ_API_KEY\")\n",
    "###print(\"Groq API Key:\", groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "52363998",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "69530bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56259bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0f99c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000028AB1646700>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000028AB1646700>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028AFFB1D280>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028B022D3E60>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'LangSmith_Search', 'description': 'Search any information about LangSmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agents\n",
    "\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3f9615bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## agent executer \n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent =agent ,tools=tools,verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e0cc017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.input_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5a0ced50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LangSmith_Search` with `{'query': 'LangSmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith docs - Docs by LangChainSkip to main contentDocs by LangChain home pageLangSmithSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APIAPI reference for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementAccess control & AuthenticationScalability & resilienceFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "\n",
      "LangSmith meets the highest standards of data security and privacy with HIPAA, SOC 2 Type 2, and GDPR compliance. For more information, see the Trust Center.\n",
      "​Workflow\n",
      "LangSmith combines observability, evaluation, deployment, and platform setup in one integrated workflow—from local development to production.\n",
      "\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "LangSmith is framework agnostic, so you can use it with or without LangChain’s open-source libraries\n",
      "langchain and langgraph.\n",
      "Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\n",
      "LangGraph Platform is now LangSmith Deployment. For more information, check out the Changelog.\n",
      "​Get started\n",
      "Create an accountSign up at smith.langchain.com (no credit card required).\n",
      "You can log in with Google, GitHub, or email.Create an API keyGo to your Settings page → API Keys → Create API Key.\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "ObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as Agent Servers, ready to scale in production.Deploy your agentsPlatform setupUse LangSmith in managed cloud, in a self-hosted environment, or hybrid to match your infrastructure and compliance needs.Choose how to set up LangSmithPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with Studio\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the response contained too much unrelated information. Let me provide you with a rewritten version that addresses your initial question.\n",
      "\n",
      "LangSmith is a tool that provides a comprehensive platform for developing, debugging, and deploying LLM (Large Language Model) applications. It offers a range of features, including observability, evaluation, deployment, and platform setup, all in one integrated workflow. With LangSmith, you can prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems. It is framework-agnostic, allowing you to use it with or without LangChain's open-source libraries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'page_content': 'Content from your PDF or document', 'input': 'Tell me about LangSmith', 'output': \"It seems like the response contained too much unrelated information. Let me provide you with a rewritten version that addresses your initial question.\\n\\nLangSmith is a tool that provides a comprehensive platform for developing, debugging, and deploying LLM (Large Language Model) applications. It offers a range of features, including observability, evaluation, deployment, and platform setup, all in one integrated workflow. With LangSmith, you can prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems. It is framework-agnostic, allowing you to use it with or without LangChain's open-source libraries.\"}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"page_content\": \"Content from your PDF or document\",\n",
    "    \"input\": \"Tell me about LangSmith\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7d16b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1706.03762'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on c\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the title, authors and summary are not available for the paper 1706.03762. The output suggests that it has something to do with sequence transduction.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Tell me about the paper 1706.03762', 'output': 'It seems like the title, authors and summary are not available for the paper 1706.03762. The output suggests that it has something to do with sequence transduction.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Tell me about the paper 1706.03762\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
